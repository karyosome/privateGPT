[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "Settings",
        "importPath": "chromadb.config",
        "description": "chromadb.config",
        "isExtraImport": true,
        "detail": "chromadb.config",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "CSVLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "EverNoteLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "PDFMinerLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "TextLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredEmailLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredEPubLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredHTMLLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredMarkdownLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredODTLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredPowerPointLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "UnstructuredWordDocumentLoader",
        "importPath": "langchain.document_loaders",
        "description": "langchain.document_loaders",
        "isExtraImport": true,
        "detail": "langchain.document_loaders",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain.vectorstores",
        "description": "langchain.vectorstores",
        "isExtraImport": true,
        "detail": "langchain.vectorstores",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain.vectorstores",
        "description": "langchain.vectorstores",
        "isExtraImport": true,
        "detail": "langchain.vectorstores",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain.embeddings",
        "description": "langchain.embeddings",
        "isExtraImport": true,
        "detail": "langchain.embeddings",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain.embeddings",
        "description": "langchain.embeddings",
        "isExtraImport": true,
        "detail": "langchain.embeddings",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.docstore.document",
        "description": "langchain.docstore.document",
        "isExtraImport": true,
        "detail": "langchain.docstore.document",
        "documentation": {}
    },
    {
        "label": "CHROMA_SETTINGS",
        "importPath": "constants",
        "description": "constants",
        "isExtraImport": true,
        "detail": "constants",
        "documentation": {}
    },
    {
        "label": "CHROMA_SETTINGS",
        "importPath": "constants",
        "description": "constants",
        "isExtraImport": true,
        "detail": "constants",
        "documentation": {}
    },
    {
        "label": "RetrievalQA",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "StreamingStdOutCallbackHandler",
        "importPath": "langchain.callbacks.streaming_stdout",
        "description": "langchain.callbacks.streaming_stdout",
        "isExtraImport": true,
        "detail": "langchain.callbacks.streaming_stdout",
        "documentation": {}
    },
    {
        "label": "GPT4All",
        "importPath": "langchain.llms",
        "description": "langchain.llms",
        "isExtraImport": true,
        "detail": "langchain.llms",
        "documentation": {}
    },
    {
        "label": "LlamaCpp",
        "importPath": "langchain.llms",
        "description": "langchain.llms",
        "isExtraImport": true,
        "detail": "langchain.llms",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "PERSIST_DIRECTORY",
        "kind": 5,
        "importPath": "constants",
        "description": "constants",
        "peekOfCode": "PERSIST_DIRECTORY = os.environ.get('PERSIST_DIRECTORY')\n# Define the Chroma settings\nCHROMA_SETTINGS = Settings(\n        chroma_db_impl='duckdb+parquet',\n        persist_directory=PERSIST_DIRECTORY,\n        anonymized_telemetry=False\n)",
        "detail": "constants",
        "documentation": {}
    },
    {
        "label": "CHROMA_SETTINGS",
        "kind": 5,
        "importPath": "constants",
        "description": "constants",
        "peekOfCode": "CHROMA_SETTINGS = Settings(\n        chroma_db_impl='duckdb+parquet',\n        persist_directory=PERSIST_DIRECTORY,\n        anonymized_telemetry=False\n)",
        "detail": "constants",
        "documentation": {}
    },
    {
        "label": "MyElmLoader",
        "kind": 6,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "class MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"\n        try:\n            try:\n                doc = UnstructuredEmailLoader.load(self)\n            except ValueError as e:\n                if 'text/html content not found in email' in str(e):\n                    # Try plain text",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "load_single_document",
        "kind": 2,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "def load_single_document(file_path: str) -> Document:\n    ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n    if ext in LOADER_MAPPING:\n        loader_class, loader_args = LOADER_MAPPING[ext]\n        loader = loader_class(file_path, **loader_args)\n        return loader.load()[0]\n    raise ValueError(f\"Unsupported file extension '{ext}'\")\ndef load_documents(source_dir: str, ignored_files: List[str] = []) -> List[Document]:\n    \"\"\"\n    Loads all documents from the source documents directory, ignoring specified files",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "load_documents",
        "kind": 2,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "def load_documents(source_dir: str, ignored_files: List[str] = []) -> List[Document]:\n    \"\"\"\n    Loads all documents from the source documents directory, ignoring specified files\n    \"\"\"\n    all_files = []\n    for ext in LOADER_MAPPING:\n        all_files.extend(\n            glob.glob(os.path.join(source_dir, f\"**/*{ext}\"), recursive=True)\n        )\n    filtered_files = [file_path for file_path in all_files if file_path not in ignored_files]",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "process_documents",
        "kind": 2,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "def process_documents(ignored_files: List[str] = []) -> List[Document]:\n    \"\"\"\n    Load documents and split in chunks\n    \"\"\"\n    print(f\"Loading documents from {source_directory}\")\n    documents = load_documents(source_directory, ignored_files)\n    if not documents:\n        print(\"No new documents to load\")\n        exit(0)\n    print(f\"Loaded {len(documents)} new documents from {source_directory}\")",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "does_vectorstore_exist",
        "kind": 2,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "def does_vectorstore_exist(persist_directory: str) -> bool:\n    \"\"\"\n    Checks if vectorstore exists\n    \"\"\"\n    if os.path.exists(os.path.join(persist_directory, 'index')):\n        if os.path.exists(os.path.join(persist_directory, 'chroma-collections.parquet')) and os.path.exists(os.path.join(persist_directory, 'chroma-embeddings.parquet')):\n            list_index_files = glob.glob(os.path.join(persist_directory, 'index/*.bin'))\n            list_index_files += glob.glob(os.path.join(persist_directory, 'index/*.pkl'))\n            # At least 3 documents are needed in a working vectorstore\n            if len(list_index_files) > 3:",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "def main():\n    # Create embeddings\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    if does_vectorstore_exist(persist_directory):\n        # Update and store locally vectorstore\n        print(f\"Appending to existing vectorstore at {persist_directory}\")\n        db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n        collection = db.get()\n        texts = process_documents([metadata['source'] for metadata in collection['metadatas']])\n        print(f\"Creating embeddings. May take some minutes...\")",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "persist_directory",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "persist_directory = os.environ.get('PERSIST_DIRECTORY')\nsource_directory = os.environ.get('SOURCE_DIRECTORY', 'source_documents')\nembeddings_model_name = os.environ.get('EMBEDDINGS_MODEL_NAME')\nchunk_size = 500\nchunk_overlap = 50\n# Custom document loaders\nclass MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "source_directory",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "source_directory = os.environ.get('SOURCE_DIRECTORY', 'source_documents')\nembeddings_model_name = os.environ.get('EMBEDDINGS_MODEL_NAME')\nchunk_size = 500\nchunk_overlap = 50\n# Custom document loaders\nclass MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"\n        try:",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "embeddings_model_name",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "embeddings_model_name = os.environ.get('EMBEDDINGS_MODEL_NAME')\nchunk_size = 500\nchunk_overlap = 50\n# Custom document loaders\nclass MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"\n        try:\n            try:",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "chunk_size",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "chunk_size = 500\nchunk_overlap = 50\n# Custom document loaders\nclass MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"\n        try:\n            try:\n                doc = UnstructuredEmailLoader.load(self)",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "chunk_overlap",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "chunk_overlap = 50\n# Custom document loaders\nclass MyElmLoader(UnstructuredEmailLoader):\n    \"\"\"Wrapper to fallback to text/plain when default does not work\"\"\"\n    def load(self) -> List[Document]:\n        \"\"\"Wrapper adding fallback for elm without html\"\"\"\n        try:\n            try:\n                doc = UnstructuredEmailLoader.load(self)\n            except ValueError as e:",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "LOADER_MAPPING",
        "kind": 5,
        "importPath": "ingest",
        "description": "ingest",
        "peekOfCode": "LOADER_MAPPING = {\n    \".csv\": (CSVLoader, {}),\n    # \".docx\": (Docx2txtLoader, {}),\n    \".doc\": (UnstructuredWordDocumentLoader, {}),\n    \".docx\": (UnstructuredWordDocumentLoader, {}),\n    \".enex\": (EverNoteLoader, {}),\n    \".eml\": (MyElmLoader, {}),\n    \".epub\": (UnstructuredEPubLoader, {}),\n    \".html\": (UnstructuredHTMLLoader, {}),\n    \".md\": (UnstructuredMarkdownLoader, {}),",
        "detail": "ingest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "def main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n    retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})\n    # activate/deactivate the streaming StdOut callback for LLMs\n    callbacks = [] if args.mute_stream else [StreamingStdOutCallbackHandler()]\n    # Prepare the LLM\n    match model_type:",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "parse_arguments",
        "kind": 2,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "def parse_arguments():\n    parser = argparse.ArgumentParser(description='privateGPT: Ask questions to your documents without an internet connection, '\n                                                 'using the power of LLMs.')\n    parser.add_argument(\"--hide-source\", \"-S\", action='store_true',\n                        help='Use this flag to disable printing of source documents used for answers.')\n    parser.add_argument(\"--mute-stream\", \"-M\",\n                        action='store_true',\n                        help='Use this flag to disable the streaming StdOut callback for LLMs.')\n    return parser.parse_args()\nif __name__ == \"__main__\":",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "embeddings_model_name",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "embeddings_model_name = os.environ.get(\"EMBEDDINGS_MODEL_NAME\")\npersist_directory = os.environ.get('PERSIST_DIRECTORY')\nmodel_type = os.environ.get('MODEL_TYPE')\nmodel_path = os.environ.get('MODEL_PATH')\nmodel_n_ctx = os.environ.get('MODEL_N_CTX')\ntarget_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "persist_directory",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "persist_directory = os.environ.get('PERSIST_DIRECTORY')\nmodel_type = os.environ.get('MODEL_TYPE')\nmodel_path = os.environ.get('MODEL_PATH')\nmodel_n_ctx = os.environ.get('MODEL_N_CTX')\ntarget_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "model_type",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "model_type = os.environ.get('MODEL_TYPE')\nmodel_path = os.environ.get('MODEL_PATH')\nmodel_n_ctx = os.environ.get('MODEL_N_CTX')\ntarget_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "model_path = os.environ.get('MODEL_PATH')\nmodel_n_ctx = os.environ.get('MODEL_N_CTX')\ntarget_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n    retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "model_n_ctx",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "model_n_ctx = os.environ.get('MODEL_N_CTX')\ntarget_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n    retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})\n    # activate/deactivate the streaming StdOut callback for LLMs",
        "detail": "privateGPT",
        "documentation": {}
    },
    {
        "label": "target_source_chunks",
        "kind": 5,
        "importPath": "privateGPT",
        "description": "privateGPT",
        "peekOfCode": "target_source_chunks = int(os.environ.get('TARGET_SOURCE_CHUNKS',4))\nfrom constants import CHROMA_SETTINGS\ndef main():\n    # Parse the command line arguments\n    args = parse_arguments()\n    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n    retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})\n    # activate/deactivate the streaming StdOut callback for LLMs\n    callbacks = [] if args.mute_stream else [StreamingStdOutCallbackHandler()]",
        "detail": "privateGPT",
        "documentation": {}
    }
]